{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drug Consumption Naive Bayes and 5-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries that I am going to use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0        1        2        3        4        5        6        7        8   \\\n",
       "0   1  0.49788  0.48246 -0.05921  0.96082  0.12600  0.31287 -0.57545 -0.58331   \n",
       "1   2 -0.07854 -0.48246  1.98437  0.96082 -0.31685 -0.67825  1.93886  1.43533   \n",
       "2   3  0.49788 -0.48246 -0.05921  0.96082 -0.31685 -0.46725  0.80523 -0.84732   \n",
       "3   4 -0.95197  0.48246  1.16365  0.96082 -0.31685 -0.14882 -0.80615 -0.01928   \n",
       "4   5  0.49788  0.48246  1.98437  0.96082 -0.31685  0.73545 -1.63340 -0.45174   \n",
       "\n",
       "        9        10       11       12   13   14   15   16   17   18   19   20  \\\n",
       "0 -0.91699 -0.00665 -0.21712 -1.18084  CL5  CL2  CL0  CL2  CL6  CL0  CL5  CL0   \n",
       "1  0.76096 -0.14277 -0.71126 -0.21575  CL5  CL2  CL2  CL0  CL6  CL4  CL6  CL3   \n",
       "2 -1.62090 -1.01450 -1.37983  0.40148  CL6  CL0  CL0  CL0  CL6  CL3  CL4  CL0   \n",
       "3  0.59042  0.58489 -1.37983 -1.18084  CL4  CL0  CL0  CL3  CL5  CL2  CL4  CL2   \n",
       "4 -0.30172  1.30612 -0.21712 -0.21575  CL4  CL1  CL1  CL0  CL6  CL3  CL6  CL0   \n",
       "\n",
       "    21   22   23   24   25   26   27   28   29   30   31  \n",
       "0  CL0  CL0  CL0  CL0  CL0  CL0  CL0  CL0  CL2  CL0  CL0  \n",
       "1  CL0  CL4  CL0  CL2  CL0  CL2  CL3  CL0  CL4  CL0  CL0  \n",
       "2  CL0  CL0  CL0  CL0  CL0  CL0  CL0  CL1  CL0  CL0  CL0  \n",
       "3  CL0  CL0  CL0  CL2  CL0  CL0  CL0  CL0  CL2  CL0  CL0  \n",
       "4  CL0  CL1  CL0  CL0  CL1  CL0  CL0  CL2  CL2  CL0  CL0  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing dataset\n",
    "df = pd.read_csv('drug_consumption.csv', header = None)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting column names\n",
    "df.columns = [\"ID\", \"Age\", \"Gender\", \"Education\", \"Country\", \"Ethnicity\", \"Nscore\", \"Escore\", \"Oscore\", \"Ascore\", \n",
    "              \"Cscore\", \"Impulsive\", \"SS\", \"Alcohol\", \"Amphet\", \"Amyl\", \"Benzos\", \"Caff\", \"Cannabis\", \"Choc\", \"Coke\", \n",
    "              \"Crack\", \"Ecstasy\", \"Heroin\", \"Ketamine\", \"Legalh\", \"LSD\", \"Meth\", \"Mushrooms\", \"Nicotine\", \"Semer\", \"VSA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Nscore</th>\n",
       "      <th>Escore</th>\n",
       "      <th>Oscore</th>\n",
       "      <th>Ascore</th>\n",
       "      <th>Cscore</th>\n",
       "      <th>Impulsive</th>\n",
       "      <th>SS</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Amphet</th>\n",
       "      <th>Amyl</th>\n",
       "      <th>Benzos</th>\n",
       "      <th>Caff</th>\n",
       "      <th>Cannabis</th>\n",
       "      <th>Choc</th>\n",
       "      <th>Coke</th>\n",
       "      <th>Crack</th>\n",
       "      <th>Ecstasy</th>\n",
       "      <th>Heroin</th>\n",
       "      <th>Ketamine</th>\n",
       "      <th>Legalh</th>\n",
       "      <th>LSD</th>\n",
       "      <th>Meth</th>\n",
       "      <th>Mushrooms</th>\n",
       "      <th>Nicotine</th>\n",
       "      <th>Semer</th>\n",
       "      <th>VSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID      Age   Gender  Education  Country  Ethnicity   Nscore   Escore  \\\n",
       "0   1  0.49788  0.48246   -0.05921  0.96082    0.12600  0.31287 -0.57545   \n",
       "1   2 -0.07854 -0.48246    1.98437  0.96082   -0.31685 -0.67825  1.93886   \n",
       "2   3  0.49788 -0.48246   -0.05921  0.96082   -0.31685 -0.46725  0.80523   \n",
       "3   4 -0.95197  0.48246    1.16365  0.96082   -0.31685 -0.14882 -0.80615   \n",
       "4   5  0.49788  0.48246    1.98437  0.96082   -0.31685  0.73545 -1.63340   \n",
       "\n",
       "    Oscore   Ascore   Cscore  Impulsive       SS Alcohol Amphet Amyl Benzos  \\\n",
       "0 -0.58331 -0.91699 -0.00665   -0.21712 -1.18084     CL5    CL2  CL0    CL2   \n",
       "1  1.43533  0.76096 -0.14277   -0.71126 -0.21575     CL5    CL2  CL2    CL0   \n",
       "2 -0.84732 -1.62090 -1.01450   -1.37983  0.40148     CL6    CL0  CL0    CL0   \n",
       "3 -0.01928  0.59042  0.58489   -1.37983 -1.18084     CL4    CL0  CL0    CL3   \n",
       "4 -0.45174 -0.30172  1.30612   -0.21712 -0.21575     CL4    CL1  CL1    CL0   \n",
       "\n",
       "  Caff Cannabis Choc Coke Crack Ecstasy Heroin Ketamine Legalh  LSD Meth  \\\n",
       "0  CL6      CL0  CL5  CL0   CL0     CL0    CL0      CL0    CL0  CL0  CL0   \n",
       "1  CL6      CL4  CL6  CL3   CL0     CL4    CL0      CL2    CL0  CL2  CL3   \n",
       "2  CL6      CL3  CL4  CL0   CL0     CL0    CL0      CL0    CL0  CL0  CL0   \n",
       "3  CL5      CL2  CL4  CL2   CL0     CL0    CL0      CL2    CL0  CL0  CL0   \n",
       "4  CL6      CL3  CL6  CL0   CL0     CL1    CL0      CL0    CL1  CL0  CL0   \n",
       "\n",
       "  Mushrooms Nicotine Semer  VSA  \n",
       "0       CL0      CL2   CL0  CL0  \n",
       "1       CL0      CL4   CL0  CL0  \n",
       "2       CL1      CL0   CL0  CL0  \n",
       "3       CL0      CL2   CL0  CL0  \n",
       "4       CL2      CL2   CL0  CL0  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CL0</th>\n",
       "      <th>CL1</th>\n",
       "      <th>CL2</th>\n",
       "      <th>CL3</th>\n",
       "      <th>CL4</th>\n",
       "      <th>CL5</th>\n",
       "      <th>CL6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alcohol</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>68</td>\n",
       "      <td>198</td>\n",
       "      <td>287</td>\n",
       "      <td>759</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amphet</th>\n",
       "      <td>976</td>\n",
       "      <td>230</td>\n",
       "      <td>243</td>\n",
       "      <td>198</td>\n",
       "      <td>75</td>\n",
       "      <td>61</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amyl</th>\n",
       "      <td>1305</td>\n",
       "      <td>210</td>\n",
       "      <td>237</td>\n",
       "      <td>92</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Benzos</th>\n",
       "      <td>1000</td>\n",
       "      <td>116</td>\n",
       "      <td>234</td>\n",
       "      <td>236</td>\n",
       "      <td>120</td>\n",
       "      <td>84</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Caff</th>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>60</td>\n",
       "      <td>106</td>\n",
       "      <td>273</td>\n",
       "      <td>1385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cannabis</th>\n",
       "      <td>413</td>\n",
       "      <td>207</td>\n",
       "      <td>266</td>\n",
       "      <td>211</td>\n",
       "      <td>140</td>\n",
       "      <td>185</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Choc</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>54</td>\n",
       "      <td>296</td>\n",
       "      <td>683</td>\n",
       "      <td>807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coke</th>\n",
       "      <td>1038</td>\n",
       "      <td>160</td>\n",
       "      <td>270</td>\n",
       "      <td>258</td>\n",
       "      <td>99</td>\n",
       "      <td>41</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crack</th>\n",
       "      <td>1627</td>\n",
       "      <td>67</td>\n",
       "      <td>112</td>\n",
       "      <td>59</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ecstasy</th>\n",
       "      <td>1021</td>\n",
       "      <td>113</td>\n",
       "      <td>234</td>\n",
       "      <td>277</td>\n",
       "      <td>156</td>\n",
       "      <td>63</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heroin</th>\n",
       "      <td>1605</td>\n",
       "      <td>68</td>\n",
       "      <td>94</td>\n",
       "      <td>65</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ketamine</th>\n",
       "      <td>1490</td>\n",
       "      <td>45</td>\n",
       "      <td>142</td>\n",
       "      <td>129</td>\n",
       "      <td>42</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Legalh</th>\n",
       "      <td>1094</td>\n",
       "      <td>29</td>\n",
       "      <td>198</td>\n",
       "      <td>323</td>\n",
       "      <td>110</td>\n",
       "      <td>64</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSD</th>\n",
       "      <td>1069</td>\n",
       "      <td>259</td>\n",
       "      <td>177</td>\n",
       "      <td>214</td>\n",
       "      <td>97</td>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meth</th>\n",
       "      <td>1429</td>\n",
       "      <td>39</td>\n",
       "      <td>97</td>\n",
       "      <td>149</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mushrooms</th>\n",
       "      <td>982</td>\n",
       "      <td>209</td>\n",
       "      <td>260</td>\n",
       "      <td>275</td>\n",
       "      <td>115</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nicotine</th>\n",
       "      <td>428</td>\n",
       "      <td>193</td>\n",
       "      <td>204</td>\n",
       "      <td>185</td>\n",
       "      <td>108</td>\n",
       "      <td>157</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VSA</th>\n",
       "      <td>1455</td>\n",
       "      <td>200</td>\n",
       "      <td>135</td>\n",
       "      <td>61</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CL0  CL1  CL2  CL3  CL4  CL5   CL6\n",
       "Alcohol      34   34   68  198  287  759   505\n",
       "Amphet      976  230  243  198   75   61   102\n",
       "Amyl       1305  210  237   92   24   14     3\n",
       "Benzos     1000  116  234  236  120   84    95\n",
       "Caff         27   10   24   60  106  273  1385\n",
       "Cannabis    413  207  266  211  140  185   463\n",
       "Choc         32    3   10   54  296  683   807\n",
       "Coke       1038  160  270  258   99   41    19\n",
       "Crack      1627   67  112   59    9    9     2\n",
       "Ecstasy    1021  113  234  277  156   63    21\n",
       "Heroin     1605   68   94   65   24   16    13\n",
       "Ketamine   1490   45  142  129   42   33     4\n",
       "Legalh     1094   29  198  323  110   64    67\n",
       "LSD        1069  259  177  214   97   56    13\n",
       "Meth       1429   39   97  149   50   48    73\n",
       "Mushrooms   982  209  260  275  115   40     4\n",
       "Nicotine    428  193  204  185  108  157   610\n",
       "VSA        1455  200  135   61   13   14     7"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many people fall into each category of user per substance? I am doing this because last time I was choose Heroin and actually\n",
    "#that was a bad choise because it's distribution is CL0 weighted\n",
    "drug_cols = ['Alcohol', 'Amphet', 'Amyl', 'Benzos', 'Caff', 'Cannabis', 'Choc', 'Coke',\n",
    "             'Crack', 'Ecstasy', 'Heroin', 'Ketamine', 'Legalh', 'LSD', 'Meth', \n",
    "            'Mushrooms', 'Nicotine', 'VSA']\n",
    "\n",
    "substance_df = df[drug_cols]\n",
    "substance_df.apply(pd.value_counts).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I am dropping columns that I don't need because I will use Cannabis as class label. And also I don't need ID column\n",
    "df = df.drop(['ID','Alcohol','Amphet','Amyl','Benzos','Caff','Choc','Coke','Crack','Ecstasy','Heroin','Ketamine','Legalh','LSD','Meth','Mushrooms','Nicotine','Semer','VSA'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age          0\n",
       "Gender       0\n",
       "Education    0\n",
       "Country      0\n",
       "Ethnicity    0\n",
       "Nscore       0\n",
       "Escore       0\n",
       "Oscore       0\n",
       "Ascore       0\n",
       "Cscore       0\n",
       "Impulsive    0\n",
       "SS           0\n",
       "Cannabis     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking null values as you can see we have no null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Age   Gender  Education  Country  Ethnicity   Nscore   Escore  \\\n",
      "0     0.49788  0.48246   -0.05921  0.96082    0.12600  0.31287 -0.57545   \n",
      "1    -0.07854 -0.48246    1.98437  0.96082   -0.31685 -0.67825  1.93886   \n",
      "2     0.49788 -0.48246   -0.05921  0.96082   -0.31685 -0.46725  0.80523   \n",
      "3    -0.95197  0.48246    1.16365  0.96082   -0.31685 -0.14882 -0.80615   \n",
      "4     0.49788  0.48246    1.98437  0.96082   -0.31685  0.73545 -1.63340   \n",
      "...       ...      ...        ...      ...        ...      ...      ...   \n",
      "1880 -0.95197  0.48246   -0.61113 -0.57009   -0.31685 -1.19430  1.74091   \n",
      "1881 -0.95197 -0.48246   -0.61113 -0.57009   -0.31685 -0.24649  1.74091   \n",
      "1882 -0.07854  0.48246    0.45468 -0.57009   -0.31685  1.13281 -1.37639   \n",
      "1883 -0.95197  0.48246   -0.61113 -0.57009   -0.31685  0.91093 -1.92173   \n",
      "1884 -0.95197 -0.48246   -0.61113  0.21128   -0.31685 -0.46725  2.12700   \n",
      "\n",
      "       Oscore   Ascore   Cscore  Impulsive       SS  \n",
      "0    -0.58331 -0.91699 -0.00665   -0.21712 -1.18084  \n",
      "1     1.43533  0.76096 -0.14277   -0.71126 -0.21575  \n",
      "2    -0.84732 -1.62090 -1.01450   -1.37983  0.40148  \n",
      "3    -0.01928  0.59042  0.58489   -1.37983 -1.18084  \n",
      "4    -0.45174 -0.30172  1.30612   -0.21712 -0.21575  \n",
      "...       ...      ...      ...        ...      ...  \n",
      "1880  1.88511  0.76096 -1.13788    0.88113  1.92173  \n",
      "1881  0.58331  0.76096 -1.51840    0.88113  0.76540  \n",
      "1882 -1.27553 -1.77200 -1.38502    0.52975 -0.52593  \n",
      "1883  0.29338 -1.62090 -2.57309    1.29221  1.22470  \n",
      "1884  1.65653  1.11406  0.41594    0.88113  1.22470  \n",
      "\n",
      "[1885 rows x 12 columns]\n",
      "0       CL0\n",
      "1       CL4\n",
      "2       CL3\n",
      "3       CL2\n",
      "4       CL3\n",
      "       ... \n",
      "1880    CL5\n",
      "1881    CL3\n",
      "1882    CL6\n",
      "1883    CL6\n",
      "1884    CL3\n",
      "Name: Cannabis, Length: 1885, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#here I am splitting my dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.iloc[:,0:12]\n",
    "print(X)\n",
    "\n",
    "y=df['Cannabis']\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I am trying to make my training and test data set\n",
    "#I am spliting them as %30 for test, %70 for training\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_C1:  0.21909814323607427\n",
      "p_C2:  0.10981432360742706\n",
      "p_C3:  0.14111405835543767\n",
      "p_C4:  0.11193633952254642\n",
      "p_C5:  0.07427055702917772\n",
      "p_C6:  0.09814323607427056\n",
      "p_C7:  0.24562334217506632\n"
     ]
    }
   ],
   "source": [
    "#Here, as a first step of naive bayes classification I am calculating the percentage distribution of our class label's values\n",
    "\n",
    "df_CL0 = df[df['Cannabis'] == 'CL0']\n",
    "df_CL1 = df[df['Cannabis'] == 'CL1']\n",
    "df_CL2 = df[df['Cannabis'] == 'CL2']\n",
    "df_CL3 = df[df['Cannabis'] == 'CL3']\n",
    "df_CL4 = df[df['Cannabis'] == 'CL4']\n",
    "df_CL5 = df[df['Cannabis'] == 'CL5']\n",
    "df_CL6 = df[df['Cannabis'] == 'CL6']\n",
    "\n",
    "\n",
    "p_C1 = df_CL0.shape[0] / df.shape[0]\n",
    "print('p_C1: ',p_C1)\n",
    "\n",
    "p_C2 = df_CL1.shape[0] / df.shape[0]\n",
    "print('p_C2: ',p_C2)\n",
    "\n",
    "p_C3 = df_CL2.shape[0] / df.shape[0]\n",
    "print('p_C3: ',p_C3)\n",
    "\n",
    "p_C4 = df_CL3.shape[0] / df.shape[0]\n",
    "print('p_C4: ',p_C4)\n",
    "\n",
    "p_C5 = df_CL4.shape[0] / df.shape[0]\n",
    "print('p_C5: ',p_C5)\n",
    "\n",
    "p_C6 = df_CL5.shape[0] / df.shape[0]\n",
    "print('p_C6: ',p_C6)\n",
    "\n",
    "p_C7 = df_CL6.shape[0] / df.shape[0]\n",
    "print('p_C7: ',p_C7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Nscore</th>\n",
       "      <th>Escore</th>\n",
       "      <th>Oscore</th>\n",
       "      <th>Ascore</th>\n",
       "      <th>Cscore</th>\n",
       "      <th>Impulsive</th>\n",
       "      <th>SS</th>\n",
       "      <th>Cannabis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>0.45468</td>\n",
       "      <td>0.24923</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>1.13281</td>\n",
       "      <td>0.16767</td>\n",
       "      <td>-0.31776</td>\n",
       "      <td>0.43852</td>\n",
       "      <td>-0.78155</td>\n",
       "      <td>0.52975</td>\n",
       "      <td>0.76540</td>\n",
       "      <td>CL6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>1.09449</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>0.13136</td>\n",
       "      <td>0.75830</td>\n",
       "      <td>-2.55524</td>\n",
       "      <td>-0.84637</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>-0.28519</td>\n",
       "      <td>-0.22166</td>\n",
       "      <td>1.02119</td>\n",
       "      <td>-1.92173</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.01729</td>\n",
       "      <td>0.41594</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-2.07848</td>\n",
       "      <td>CL2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.28519</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-2.21844</td>\n",
       "      <td>0.96248</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.13136</td>\n",
       "      <td>1.63088</td>\n",
       "      <td>-2.55524</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>CL5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>0.45468</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.58016</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>0.44585</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>0.76540</td>\n",
       "      <td>CL5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>0.45468</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.41667</td>\n",
       "      <td>-0.15487</td>\n",
       "      <td>-0.31776</td>\n",
       "      <td>2.23427</td>\n",
       "      <td>1.13407</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-0.52593</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.92104</td>\n",
       "      <td>1.45421</td>\n",
       "      <td>1.65653</td>\n",
       "      <td>-0.01729</td>\n",
       "      <td>-0.52745</td>\n",
       "      <td>1.86203</td>\n",
       "      <td>1.92173</td>\n",
       "      <td>CL6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.82562</td>\n",
       "      <td>-0.43999</td>\n",
       "      <td>0.88309</td>\n",
       "      <td>0.43852</td>\n",
       "      <td>-0.52745</td>\n",
       "      <td>0.52975</td>\n",
       "      <td>1.22470</td>\n",
       "      <td>CL6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.04257</td>\n",
       "      <td>-0.43999</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.65253</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>CL5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-0.69509</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>2.03972</td>\n",
       "      <td>-0.40581</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>1.92173</td>\n",
       "      <td>CL5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1319 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age   Gender  Education  Country  Ethnicity   Nscore   Escore  \\\n",
       "1370 -0.07854 -0.48246    0.45468  0.24923   -0.31685  1.13281  0.16767   \n",
       "442   1.09449  0.48246   -0.05921  0.96082   -0.31685 -0.46725  0.80523   \n",
       "552  -0.07854  0.48246    1.16365 -0.28519   -0.22166  1.02119 -1.92173   \n",
       "1726 -0.95197 -0.48246   -0.61113 -0.28519   -0.31685 -2.21844  0.96248   \n",
       "794  -0.95197  0.48246    0.45468  0.96082   -0.31685 -0.58016  0.80523   \n",
       "...       ...      ...        ...      ...        ...      ...      ...   \n",
       "630  -0.95197  0.48246    0.45468  0.96082   -0.31685  0.41667 -0.15487   \n",
       "1475 -0.95197 -0.48246   -0.61113 -0.57009   -0.31685 -0.92104  1.45421   \n",
       "780  -0.95197  0.48246   -0.61113 -0.57009   -0.31685  0.82562 -0.43999   \n",
       "1097 -0.95197  0.48246   -0.61113 -0.57009   -0.31685  0.04257 -0.43999   \n",
       "1452 -0.95197 -0.48246   -0.05921 -0.57009   -0.31685  0.73545 -0.69509   \n",
       "\n",
       "       Oscore   Ascore   Cscore  Impulsive       SS Cannabis  \n",
       "1370 -0.31776  0.43852 -0.78155    0.52975  0.76540      CL6  \n",
       "442   0.58331  0.13136  0.75830   -2.55524 -0.84637      CL0  \n",
       "552  -0.45174 -0.01729  0.41594   -0.71126 -2.07848      CL2  \n",
       "1726 -0.01928  0.13136  1.63088   -2.55524 -0.21575      CL5  \n",
       "794   0.44585  0.59042  1.30612   -0.71126  0.76540      CL5  \n",
       "...       ...      ...      ...        ...      ...      ...  \n",
       "630  -0.31776  2.23427  1.13407   -1.37983 -0.52593      CL0  \n",
       "1475  1.65653 -0.01729 -0.52745    1.86203  1.92173      CL6  \n",
       "780   0.88309  0.43852 -0.52745    0.52975  1.22470      CL6  \n",
       "1097 -0.01928 -0.91699 -0.65253   -1.37983 -0.21575      CL5  \n",
       "1452  1.43533  2.03972 -0.40581   -0.71126  1.92173      CL5  \n",
       "\n",
       "[1319 rows x 13 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here I am reassembling the dataset because I will make my calculations for the values in the class label.\n",
    "Xtrain = pd.concat([X_train, y_train], axis=1) \n",
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age          0.444258\n",
      "Gender       0.226941\n",
      "Education    0.244361\n",
      "Country      0.831845\n",
      "Ethnicity   -0.356703\n",
      "Nscore      -0.190437\n",
      "Escore       0.104773\n",
      "Oscore      -0.571397\n",
      "Ascore       0.284853\n",
      "Cscore       0.440236\n",
      "Impulsive   -0.449112\n",
      "SS          -0.629611\n",
      "dtype: float64\n",
      "Age          0.876221\n",
      "Gender       0.426496\n",
      "Education    0.969213\n",
      "Country      0.382211\n",
      "Ethnicity    0.213985\n",
      "Nscore       0.931544\n",
      "Escore       0.946232\n",
      "Oscore       0.875703\n",
      "Ascore       0.947615\n",
      "Cscore       0.870642\n",
      "Impulsive    0.867730\n",
      "SS           0.844778\n",
      "dtype: float64\n",
      "Age          0.737881\n",
      "Gender       0.093812\n",
      "Education    0.371274\n",
      "Country      0.780917\n",
      "Ethnicity   -0.310984\n",
      "Nscore      -0.140469\n",
      "Escore      -0.053732\n",
      "Oscore      -0.352696\n",
      "Ascore       0.127109\n",
      "Cscore       0.257222\n",
      "Impulsive   -0.314059\n",
      "SS          -0.414560\n",
      "dtype: float64\n",
      "Age          0.621926\n",
      "Gender       0.474903\n",
      "Education    1.020585\n",
      "Country      0.457541\n",
      "Ethnicity    0.068712\n",
      "Nscore       0.972658\n",
      "Escore       0.937135\n",
      "Oscore       0.970075\n",
      "Ascore       0.857421\n",
      "Cscore       0.959552\n",
      "Impulsive    0.866823\n",
      "SS           0.816657\n",
      "dtype: float64\n",
      "Age          0.172180\n",
      "Gender       0.113669\n",
      "Education    0.263306\n",
      "Country      0.629197\n",
      "Ethnicity   -0.308524\n",
      "Nscore       0.062780\n",
      "Escore      -0.021645\n",
      "Oscore      -0.269773\n",
      "Ascore      -0.093799\n",
      "Cscore       0.016738\n",
      "Impulsive   -0.041470\n",
      "SS          -0.203829\n",
      "dtype: float64\n",
      "Age          0.741271\n",
      "Gender       0.470111\n",
      "Education    0.832339\n",
      "Country      0.584802\n",
      "Ethnicity    0.119028\n",
      "Nscore       0.988338\n",
      "Escore       1.002238\n",
      "Oscore       0.875820\n",
      "Ascore       0.984536\n",
      "Cscore       0.939771\n",
      "Impulsive    0.913342\n",
      "SS           0.920225\n",
      "dtype: float64\n",
      "Age         -0.105771\n",
      "Gender      -0.020386\n",
      "Education    0.050738\n",
      "Country      0.252113\n",
      "Ethnicity   -0.304193\n",
      "Nscore       0.272720\n",
      "Escore      -0.202331\n",
      "Oscore       0.074072\n",
      "Ascore      -0.098004\n",
      "Cscore      -0.280058\n",
      "Impulsive    0.122948\n",
      "SS           0.175776\n",
      "dtype: float64\n",
      "Age          0.782297\n",
      "Gender       0.483735\n",
      "Education    0.945832\n",
      "Country      0.718222\n",
      "Ethnicity    0.110366\n",
      "Nscore       1.025163\n",
      "Escore       1.062627\n",
      "Oscore       0.960028\n",
      "Ascore       0.989817\n",
      "Cscore       0.917881\n",
      "Impulsive    0.965024\n",
      "SS           0.889140\n",
      "dtype: float64\n",
      "Age         -0.360616\n",
      "Gender      -0.195850\n",
      "Education   -0.266297\n",
      "Country     -0.023187\n",
      "Ethnicity   -0.256462\n",
      "Nscore       0.081962\n",
      "Escore      -0.081610\n",
      "Oscore       0.206892\n",
      "Ascore      -0.186894\n",
      "Cscore      -0.343188\n",
      "Impulsive    0.352959\n",
      "SS           0.379883\n",
      "dtype: float64\n",
      "Age          0.773017\n",
      "Gender       0.443119\n",
      "Education    0.776387\n",
      "Country      0.646705\n",
      "Ethnicity    0.270221\n",
      "Nscore       1.095016\n",
      "Escore       1.152749\n",
      "Oscore       0.962799\n",
      "Ascore       1.053859\n",
      "Cscore       0.968412\n",
      "Impulsive    0.973104\n",
      "SS           0.789369\n",
      "dtype: float64\n",
      "Age         -0.497768\n",
      "Gender      -0.177748\n",
      "Education   -0.243917\n",
      "Country      0.021206\n",
      "Ethnicity   -0.318666\n",
      "Nscore       0.022475\n",
      "Escore       0.074362\n",
      "Oscore       0.371116\n",
      "Ascore      -0.011177\n",
      "Cscore      -0.188201\n",
      "Impulsive    0.249277\n",
      "SS           0.488239\n",
      "dtype: float64\n",
      "Age          0.691805\n",
      "Gender       0.450219\n",
      "Education    0.911519\n",
      "Country      0.674446\n",
      "Ethnicity    0.142305\n",
      "Nscore       1.037840\n",
      "Escore       1.139607\n",
      "Oscore       0.920220\n",
      "Ascore       1.085491\n",
      "Cscore       1.005455\n",
      "Impulsive    0.950520\n",
      "SS           0.791386\n",
      "dtype: float64\n",
      "Age         -0.384977\n",
      "Gender      -0.166832\n",
      "Education   -0.376697\n",
      "Country     -0.150349\n",
      "Ethnicity   -0.285562\n",
      "Nscore       0.023605\n",
      "Escore       0.027177\n",
      "Oscore       0.480044\n",
      "Ascore      -0.133351\n",
      "Cscore      -0.228091\n",
      "Impulsive    0.261497\n",
      "SS           0.409191\n",
      "dtype: float64\n",
      "Age          0.766813\n",
      "Gender       0.453404\n",
      "Education    0.855042\n",
      "Country      0.615175\n",
      "Ethnicity    0.175575\n",
      "Nscore       1.036588\n",
      "Escore       0.990153\n",
      "Oscore       0.853167\n",
      "Ascore       0.994310\n",
      "Cscore       0.961267\n",
      "Impulsive    0.845447\n",
      "SS           0.842371\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculating likelihoods based on Gaussian Distribution\n",
    "# p_x_C = (1 / (sqrt(2 x Pi x std^2))) x exp(-(x - m)^2 / (2 x std^2))\n",
    "# calculating mean and std for each class first\n",
    "\n",
    "\n",
    "mean_C1 =  Xtrain[Xtrain['Cannabis']=='CL0'].iloc[:,0:12].mean()\n",
    "std_C1 = Xtrain[Xtrain['Cannabis']=='CL0'].iloc[:,0:12].std()\n",
    "print(mean_C1)\n",
    "print(std_C1)\n",
    "\n",
    "mean_C2 =  Xtrain[Xtrain['Cannabis']=='CL1'].iloc[:,0:12].mean()\n",
    "std_C2 = Xtrain[Xtrain['Cannabis']=='CL1'].iloc[:,0:12].std()\n",
    "print(mean_C2)\n",
    "print(std_C2)\n",
    "\n",
    "mean_C3 =  Xtrain[Xtrain['Cannabis']=='CL2'].iloc[:,0:12].mean()\n",
    "std_C3 = Xtrain[Xtrain['Cannabis']=='CL2'].iloc[:,0:12].std()\n",
    "print(mean_C3)\n",
    "print(std_C3)\n",
    "\n",
    "mean_C4 =  Xtrain[Xtrain['Cannabis']=='CL3'].iloc[:,0:12].mean()\n",
    "std_C4 = Xtrain[Xtrain['Cannabis']=='CL3'].iloc[:,0:12].std()\n",
    "print(mean_C4)\n",
    "print(std_C4)\n",
    "\n",
    "mean_C5 =  Xtrain[Xtrain['Cannabis']=='CL4'].iloc[:,0:12].mean()\n",
    "std_C5 = Xtrain[Xtrain['Cannabis']=='CL4'].iloc[:,0:12].std()\n",
    "print(mean_C5)\n",
    "print(std_C5)\n",
    "\n",
    "mean_C6 =  Xtrain[Xtrain['Cannabis']=='CL5'].iloc[:,0:12].mean()\n",
    "std_C6 = Xtrain[Xtrain['Cannabis']=='CL5'].iloc[:,0:12].std()\n",
    "print(mean_C6)\n",
    "print(std_C6)\n",
    "\n",
    "mean_C7 =  Xtrain[Xtrain['Cannabis']=='CL6'].iloc[:,0:12].mean()\n",
    "std_C7 = Xtrain[Xtrain['Cannabis']=='CL6'].iloc[:,0:12].std()\n",
    "print(mean_C7)\n",
    "print(std_C7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CL6', 'CL0', 'CL6', 'CL0', 'CL1', 'CL3', 'CL0', 'CL1', 'CL6', 'CL3', 'CL6', 'CL0', 'CL2', 'CL1', 'CL0', 'CL1', 'CL0', 'CL6', 'CL0', 'CL1', 'CL0', 'CL0', 'CL2', 'CL6', 'CL6', 'CL6', 'CL6', 'CL6', 'CL0', 'CL6', 'CL2', 'CL1', 'CL1', 'CL1', 'CL3', 'CL2', 'CL3', 'CL6', 'CL6', 'CL3', 'CL0', 'CL5', 'CL1', 'CL0', 'CL6', 'CL4', 'CL3', 'CL6', 'CL1', 'CL6', 'CL4', 'CL6', 'CL2', 'CL4', 'CL2', 'CL5', 'CL6', 'CL3', 'CL6', 'CL3', 'CL0', 'CL6', 'CL1', 'CL6', 'CL6', 'CL1', 'CL1', 'CL4', 'CL0', 'CL6', 'CL5', 'CL5', 'CL0', 'CL0', 'CL1', 'CL6', 'CL0', 'CL0', 'CL0', 'CL0', 'CL6', 'CL3', 'CL6', 'CL6', 'CL2', 'CL6', 'CL6', 'CL6', 'CL6', 'CL4', 'CL6', 'CL1', 'CL6', 'CL4', 'CL0', 'CL3', 'CL6', 'CL1', 'CL5', 'CL0', 'CL0', 'CL2', 'CL6', 'CL3', 'CL3', 'CL1', 'CL0', 'CL6', 'CL1', 'CL3', 'CL0', 'CL0', 'CL0', 'CL4', 'CL4', 'CL6', 'CL2', 'CL1', 'CL1', 'CL6', 'CL1', 'CL6', 'CL2', 'CL1', 'CL0', 'CL0', 'CL3', 'CL6', 'CL1', 'CL1', 'CL0', 'CL6', 'CL6', 'CL1', 'CL0', 'CL6', 'CL6', 'CL6', 'CL1', 'CL0', 'CL6', 'CL6', 'CL1', 'CL3', 'CL6', 'CL3', 'CL6', 'CL3', 'CL6', 'CL3', 'CL1', 'CL1', 'CL4', 'CL0', 'CL1', 'CL1', 'CL2', 'CL6', 'CL6', 'CL2', 'CL2', 'CL6', 'CL6', 'CL3', 'CL6', 'CL2', 'CL1', 'CL0', 'CL1', 'CL2', 'CL0', 'CL1', 'CL5', 'CL3', 'CL6', 'CL5', 'CL1', 'CL1', 'CL6', 'CL6', 'CL1', 'CL2', 'CL0', 'CL4', 'CL6', 'CL0', 'CL4', 'CL0', 'CL5', 'CL0', 'CL6', 'CL6', 'CL0', 'CL1', 'CL1', 'CL1', 'CL6', 'CL4', 'CL4', 'CL1', 'CL1', 'CL6', 'CL4', 'CL0', 'CL3', 'CL6', 'CL2', 'CL6', 'CL0', 'CL1', 'CL0', 'CL0', 'CL6', 'CL3', 'CL6', 'CL1', 'CL6', 'CL1', 'CL1', 'CL4', 'CL0', 'CL6', 'CL1', 'CL1', 'CL0', 'CL6', 'CL1', 'CL6', 'CL2', 'CL0', 'CL3', 'CL3', 'CL6', 'CL3', 'CL1', 'CL0', 'CL6', 'CL6', 'CL1', 'CL0', 'CL4', 'CL6', 'CL0', 'CL6', 'CL6', 'CL3', 'CL0', 'CL4', 'CL5', 'CL4', 'CL1', 'CL2', 'CL3', 'CL1', 'CL6', 'CL4', 'CL3', 'CL6', 'CL1', 'CL4', 'CL1', 'CL2', 'CL2', 'CL1', 'CL6', 'CL1', 'CL0', 'CL0', 'CL6', 'CL0', 'CL6', 'CL1', 'CL1', 'CL0', 'CL4', 'CL1', 'CL0', 'CL6', 'CL6', 'CL6', 'CL6', 'CL0', 'CL1', 'CL0', 'CL5', 'CL2', 'CL1', 'CL1', 'CL3', 'CL0', 'CL6', 'CL0', 'CL3', 'CL6', 'CL1', 'CL4', 'CL4', 'CL6', 'CL1', 'CL6', 'CL1', 'CL1', 'CL6', 'CL6', 'CL3', 'CL2', 'CL0', 'CL0', 'CL3', 'CL1', 'CL1', 'CL3', 'CL2', 'CL5', 'CL6', 'CL6', 'CL3', 'CL3', 'CL0', 'CL1', 'CL1', 'CL2', 'CL1', 'CL0', 'CL4', 'CL3', 'CL6', 'CL1', 'CL6', 'CL2', 'CL0', 'CL6', 'CL0', 'CL6', 'CL5', 'CL6', 'CL6', 'CL6', 'CL6', 'CL1', 'CL2', 'CL2', 'CL6', 'CL0', 'CL1', 'CL4', 'CL1', 'CL1', 'CL0', 'CL1', 'CL0', 'CL2', 'CL6', 'CL0', 'CL1', 'CL1', 'CL0', 'CL0', 'CL0', 'CL6', 'CL2', 'CL6', 'CL1', 'CL1', 'CL1', 'CL0', 'CL0', 'CL1', 'CL5', 'CL0', 'CL1', 'CL0', 'CL1', 'CL6', 'CL3', 'CL6', 'CL2', 'CL6', 'CL6', 'CL2', 'CL2', 'CL1', 'CL1', 'CL0', 'CL0', 'CL0', 'CL3', 'CL6', 'CL1', 'CL6', 'CL1', 'CL1', 'CL0', 'CL6', 'CL1', 'CL6', 'CL6', 'CL0', 'CL5', 'CL0', 'CL0', 'CL6', 'CL6', 'CL3', 'CL1', 'CL6', 'CL0', 'CL6', 'CL2', 'CL6', 'CL1', 'CL1', 'CL3', 'CL6', 'CL6', 'CL0', 'CL1', 'CL3', 'CL6', 'CL0', 'CL3', 'CL6', 'CL3', 'CL1', 'CL3', 'CL3', 'CL0', 'CL2', 'CL0', 'CL1', 'CL6', 'CL0', 'CL6', 'CL6', 'CL6', 'CL6', 'CL2', 'CL5', 'CL0', 'CL6', 'CL0', 'CL1', 'CL1', 'CL1', 'CL3', 'CL4', 'CL2', 'CL6', 'CL1', 'CL5', 'CL3', 'CL0', 'CL5', 'CL5', 'CL1', 'CL1', 'CL2', 'CL1', 'CL3', 'CL0', 'CL2', 'CL6', 'CL0', 'CL6', 'CL3', 'CL4', 'CL1', 'CL5', 'CL0', 'CL5', 'CL6', 'CL2', 'CL6', 'CL1', 'CL6', 'CL2', 'CL6', 'CL6', 'CL2', 'CL3', 'CL5', 'CL1', 'CL1', 'CL3', 'CL0', 'CL2', 'CL6', 'CL0', 'CL1', 'CL0', 'CL0', 'CL1', 'CL0', 'CL6', 'CL0', 'CL0', 'CL6', 'CL6', 'CL4', 'CL0', 'CL6', 'CL6', 'CL1', 'CL5', 'CL3', 'CL5', 'CL2', 'CL6', 'CL1', 'CL5', 'CL6', 'CL2', 'CL3', 'CL0', 'CL1', 'CL1', 'CL3', 'CL2', 'CL1', 'CL2', 'CL0', 'CL6', 'CL5', 'CL3', 'CL1', 'CL5', 'CL2', 'CL1', 'CL3', 'CL0', 'CL3', 'CL1', 'CL6', 'CL2', 'CL6', 'CL6', 'CL2', 'CL6', 'CL1', 'CL0', 'CL3', 'CL1', 'CL1', 'CL5', 'CL4', 'CL1', 'CL0', 'CL6', 'CL2', 'CL0', 'CL5', 'CL0', 'CL3', 'CL6', 'CL6', 'CL4', 'CL5', 'CL6', 'CL1', 'CL6', 'CL3', 'CL2', 'CL1', 'CL6', 'CL6', 'CL3']\n",
      "0.3586572438162544\n"
     ]
    }
   ],
   "source": [
    "#Since there was an error here, we edited the formula with Umut like this and calculated the probabilities for all values\n",
    "X_test_arr = X_test.to_numpy()\n",
    "pred = []\n",
    "for test in X_test_arr:\n",
    "    p_x_C1 = (1 / ((2 * math.pi * std_C1**2)**0.5)) * 2.7182**(-1 * (test - mean_C1)**2 / (2 * std_C1**2))   \n",
    "    \n",
    "    p_x_C2 = (1 / ((2 * math.pi * std_C2**2)**0.5)) * 2.7182**(-1 * (test - mean_C2)**2 / (2 * std_C2**2))\n",
    " \n",
    "    p_x_C3 = (1 / ((2 * math.pi * std_C3**2)**0.5)) * 2.7182**(-1 * (test - mean_C3)**2 / (2 * std_C3**2))\n",
    "    \n",
    "    p_x_C4 = (1 / ((2 * math.pi * std_C4**2)**0.5)) * 2.7182**(-1 * (test - mean_C4)**2 / (2 * std_C4**2))\n",
    "    \n",
    "    p_x_C5 = (1 / ((2 * math.pi * std_C4**2)**0.5)) * 2.7182**(-1 * (test - mean_C5)**2 / (2 * std_C5**2))\n",
    "    \n",
    "    p_x_C6 = (1 / ((2 * math.pi * std_C4**2)**0.5)) * 2.7182**(-1 * (test - mean_C6)**2 / (2 * std_C6**2))\n",
    "    \n",
    "    p_x_C7 = (1 / ((2 * math.pi * std_C4**2)**0.5)) * 2.7182**(-1 * (test - mean_C7)**2 / (2 * std_C7**2))\n",
    "    \n",
    "    p_x = p_x_C1.prod() * p_C1 + p_x_C2.prod() * p_C2 + p_x_C3.prod() * p_C3 + p_x_C4.prod() * p_C4 + p_x_C5.prod() * p_C5 + p_x_C6.prod() * p_C6 + p_x_C7.prod() * p_C7\n",
    "    p_x\n",
    "    \n",
    "\n",
    "    p_C1_x = p_x_C1.prod() * p_C1 / p_x\n",
    "    p_C2_x = p_x_C2.prod() * p_C2 / p_x\n",
    "    p_C3_x = p_x_C3.prod() * p_C3 / p_x\n",
    "    p_C4_x = p_x_C4.prod() * p_C4 / p_x\n",
    "    p_C5_x = p_x_C5.prod() * p_C5 / p_x\n",
    "    p_C6_x = p_x_C6.prod() * p_C6 / p_x\n",
    "    p_C7_x = p_x_C7.prod() * p_C7 / p_x\n",
    "    \n",
    "    highest = max(p_C1_x, p_C2_x, p_C3_x, p_C4_x, p_C5_x, p_C6_x, p_C7_x)\n",
    "    \n",
    "    if(highest==p_C1_x):\n",
    "        pred.append('CL0')\n",
    "        \n",
    "    if(highest==p_C2_x):\n",
    "        pred.append('CL1')\n",
    "        \n",
    "    if(highest==p_C3_x):\n",
    "        pred.append('CL2')\n",
    "        \n",
    "    if(highest==p_C4_x):\n",
    "        pred.append('CL3')\n",
    "        \n",
    "    if(highest==p_C5_x):\n",
    "        pred.append('CL4')\n",
    "        \n",
    "    if(highest==p_C6_x):\n",
    "        pred.append('CL5')\n",
    "        \n",
    "    if(highest==p_C7_x):\n",
    "        pred.append('CL6')   \n",
    "        \n",
    "print(pred)\n",
    "t = 0\n",
    "z = 0\n",
    "for f, b in zip(pred, y_test):\n",
    "    if(f == b):\n",
    "        t += 1\n",
    "    else:\n",
    "        z+=1\n",
    "print(t/(t+z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CL6' 'CL0' 'CL6' 'CL0' 'CL1' 'CL3' 'CL0' 'CL1' 'CL6' 'CL3' 'CL6' 'CL0'\n",
      " 'CL2' 'CL1' 'CL0' 'CL1' 'CL0' 'CL6' 'CL0' 'CL1' 'CL0' 'CL0' 'CL2' 'CL6'\n",
      " 'CL6' 'CL6' 'CL6' 'CL6' 'CL0' 'CL6' 'CL2' 'CL1' 'CL0' 'CL1' 'CL3' 'CL2'\n",
      " 'CL3' 'CL6' 'CL6' 'CL6' 'CL1' 'CL6' 'CL1' 'CL0' 'CL6' 'CL6' 'CL3' 'CL6'\n",
      " 'CL1' 'CL6' 'CL6' 'CL6' 'CL1' 'CL6' 'CL2' 'CL6' 'CL6' 'CL3' 'CL6' 'CL3'\n",
      " 'CL0' 'CL6' 'CL1' 'CL6' 'CL6' 'CL1' 'CL1' 'CL6' 'CL0' 'CL6' 'CL5' 'CL5'\n",
      " 'CL0' 'CL0' 'CL1' 'CL6' 'CL0' 'CL0' 'CL1' 'CL0' 'CL3' 'CL6' 'CL6' 'CL6'\n",
      " 'CL6' 'CL6' 'CL6' 'CL6' 'CL6' 'CL6' 'CL6' 'CL2' 'CL6' 'CL4' 'CL0' 'CL6'\n",
      " 'CL6' 'CL1' 'CL5' 'CL0' 'CL0' 'CL2' 'CL6' 'CL3' 'CL3' 'CL1' 'CL1' 'CL6'\n",
      " 'CL1' 'CL3' 'CL1' 'CL1' 'CL0' 'CL6' 'CL6' 'CL6' 'CL2' 'CL1' 'CL1' 'CL6'\n",
      " 'CL0' 'CL6' 'CL2' 'CL1' 'CL0' 'CL0' 'CL3' 'CL6' 'CL1' 'CL1' 'CL0' 'CL6'\n",
      " 'CL6' 'CL1' 'CL0' 'CL6' 'CL6' 'CL6' 'CL2' 'CL0' 'CL6' 'CL3' 'CL1' 'CL3'\n",
      " 'CL6' 'CL3' 'CL6' 'CL3' 'CL6' 'CL3' 'CL1' 'CL1' 'CL4' 'CL1' 'CL1' 'CL1'\n",
      " 'CL2' 'CL6' 'CL6' 'CL2' 'CL2' 'CL6' 'CL3' 'CL3' 'CL6' 'CL2' 'CL1' 'CL0'\n",
      " 'CL1' 'CL2' 'CL0' 'CL1' 'CL5' 'CL2' 'CL6' 'CL6' 'CL1' 'CL1' 'CL6' 'CL6'\n",
      " 'CL1' 'CL2' 'CL0' 'CL6' 'CL6' 'CL0' 'CL6' 'CL0' 'CL0' 'CL0' 'CL6' 'CL6'\n",
      " 'CL0' 'CL1' 'CL1' 'CL1' 'CL6' 'CL6' 'CL6' 'CL1' 'CL1' 'CL6' 'CL6' 'CL0'\n",
      " 'CL3' 'CL6' 'CL2' 'CL6' 'CL0' 'CL1' 'CL0' 'CL0' 'CL6' 'CL6' 'CL6' 'CL1'\n",
      " 'CL6' 'CL1' 'CL1' 'CL6' 'CL0' 'CL6' 'CL1' 'CL1' 'CL0' 'CL6' 'CL1' 'CL6'\n",
      " 'CL2' 'CL0' 'CL3' 'CL3' 'CL6' 'CL3' 'CL1' 'CL0' 'CL6' 'CL6' 'CL1' 'CL0'\n",
      " 'CL6' 'CL6' 'CL1' 'CL6' 'CL6' 'CL2' 'CL0' 'CL6' 'CL3' 'CL4' 'CL1' 'CL2'\n",
      " 'CL3' 'CL1' 'CL6' 'CL4' 'CL3' 'CL6' 'CL1' 'CL6' 'CL1' 'CL2' 'CL2' 'CL1'\n",
      " 'CL6' 'CL1' 'CL0' 'CL0' 'CL2' 'CL0' 'CL3' 'CL1' 'CL1' 'CL0' 'CL6' 'CL1'\n",
      " 'CL0' 'CL6' 'CL6' 'CL6' 'CL6' 'CL0' 'CL1' 'CL0' 'CL5' 'CL2' 'CL2' 'CL1'\n",
      " 'CL6' 'CL0' 'CL6' 'CL1' 'CL3' 'CL3' 'CL1' 'CL3' 'CL6' 'CL6' 'CL2' 'CL6'\n",
      " 'CL1' 'CL1' 'CL6' 'CL6' 'CL3' 'CL2' 'CL0' 'CL0' 'CL3' 'CL1' 'CL1' 'CL3'\n",
      " 'CL2' 'CL6' 'CL2' 'CL6' 'CL3' 'CL3' 'CL1' 'CL1' 'CL1' 'CL3' 'CL1' 'CL0'\n",
      " 'CL6' 'CL3' 'CL6' 'CL1' 'CL3' 'CL2' 'CL0' 'CL6' 'CL0' 'CL6' 'CL6' 'CL6'\n",
      " 'CL6' 'CL6' 'CL6' 'CL1' 'CL2' 'CL3' 'CL3' 'CL0' 'CL1' 'CL6' 'CL1' 'CL1'\n",
      " 'CL0' 'CL1' 'CL1' 'CL2' 'CL6' 'CL0' 'CL1' 'CL1' 'CL0' 'CL0' 'CL0' 'CL6'\n",
      " 'CL2' 'CL6' 'CL1' 'CL1' 'CL1' 'CL1' 'CL1' 'CL1' 'CL6' 'CL0' 'CL1' 'CL0'\n",
      " 'CL1' 'CL6' 'CL2' 'CL6' 'CL2' 'CL6' 'CL6' 'CL1' 'CL2' 'CL1' 'CL1' 'CL0'\n",
      " 'CL1' 'CL1' 'CL3' 'CL6' 'CL1' 'CL6' 'CL1' 'CL1' 'CL0' 'CL6' 'CL2' 'CL6'\n",
      " 'CL6' 'CL1' 'CL6' 'CL0' 'CL2' 'CL6' 'CL6' 'CL3' 'CL1' 'CL6' 'CL0' 'CL6'\n",
      " 'CL2' 'CL6' 'CL1' 'CL1' 'CL3' 'CL6' 'CL6' 'CL0' 'CL1' 'CL6' 'CL6' 'CL0'\n",
      " 'CL3' 'CL6' 'CL6' 'CL1' 'CL3' 'CL3' 'CL0' 'CL2' 'CL0' 'CL1' 'CL6' 'CL0'\n",
      " 'CL6' 'CL6' 'CL6' 'CL6' 'CL1' 'CL6' 'CL0' 'CL6' 'CL0' 'CL1' 'CL1' 'CL1'\n",
      " 'CL3' 'CL6' 'CL6' 'CL6' 'CL1' 'CL3' 'CL3' 'CL0' 'CL6' 'CL6' 'CL1' 'CL1'\n",
      " 'CL2' 'CL1' 'CL3' 'CL2' 'CL2' 'CL6' 'CL0' 'CL6' 'CL3' 'CL6' 'CL1' 'CL6'\n",
      " 'CL0' 'CL1' 'CL6' 'CL2' 'CL6' 'CL2' 'CL6' 'CL1' 'CL6' 'CL6' 'CL2' 'CL3'\n",
      " 'CL5' 'CL1' 'CL1' 'CL3' 'CL0' 'CL2' 'CL6' 'CL0' 'CL1' 'CL0' 'CL1' 'CL1'\n",
      " 'CL0' 'CL6' 'CL0' 'CL0' 'CL6' 'CL6' 'CL3' 'CL1' 'CL6' 'CL6' 'CL1' 'CL6'\n",
      " 'CL3' 'CL5' 'CL2' 'CL6' 'CL1' 'CL5' 'CL6' 'CL2' 'CL3' 'CL0' 'CL1' 'CL1'\n",
      " 'CL3' 'CL2' 'CL1' 'CL2' 'CL0' 'CL6' 'CL6' 'CL6' 'CL1' 'CL5' 'CL2' 'CL1'\n",
      " 'CL3' 'CL0' 'CL3' 'CL1' 'CL6' 'CL2' 'CL6' 'CL6' 'CL2' 'CL6' 'CL1' 'CL0'\n",
      " 'CL3' 'CL1' 'CL1' 'CL5' 'CL6' 'CL1' 'CL0' 'CL6' 'CL1' 'CL0' 'CL6' 'CL0'\n",
      " 'CL3' 'CL6' 'CL6' 'CL6' 'CL3' 'CL6' 'CL1' 'CL6' 'CL3' 'CL3' 'CL1' 'CL6'\n",
      " 'CL6' 'CL3']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4134275618374558"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we are looking at our results using the sklearn library. Our results are generally the same when comparing the naive bayes\n",
    "#classification that we made previously. But This one's accuracy is a bit more.\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "\n",
    "myGNB = gnb.fit(X,np.ravel(y))\n",
    "y_pred = myGNB.predict(X_test)\n",
    "print(y_pred)\n",
    "myGNB.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold cross validation for Decision Tree Classifier: 0.2625994694960212\n",
      "5 fold cross validation for Decision Tree Classifier: 0.32625994694960214\n",
      "5 fold cross validation for Decision Tree Classifier: 0.27320954907161804\n",
      "5 fold cross validation for Decision Tree Classifier: 0.2838196286472148\n",
      "5 fold cross validation for Decision Tree Classifier: 0.32625994694960214\n",
      "Accuracy for Decision Tree Classifier: 0.29442970822281167\n"
     ]
    }
   ],
   "source": [
    "#here I am importing StratifiedKFold because my class labels includes string values\n",
    "#so that this library is really usefull for me. After I am splitting the into 5 pieces then starting process\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "X_data = X.values\n",
    "y_data = y.values\n",
    "skf.get_n_splits(X_data)\n",
    "#Here I am using DecisionTreeClassifier from sklearn library and calculating 5-fold cross validation and accuracy\n",
    "#also I am saving my results in dt_5fold_accuracies array for later visualisaion\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "accuracy_dt = 0\n",
    "dt_5fold_values=[]\n",
    "for train_index, test_index in skf.split(X_data, y_data):\n",
    "    X_train, X_test = X_data[train_index], X_data[test_index]\n",
    "    y_train, y_test = y_data[train_index], y_data[test_index]\n",
    "    \n",
    "    ##Decision Tree\n",
    "    msl=[]\n",
    "    tree = DecisionTreeClassifier()\n",
    "    t= tree.fit(X_train, y_train)\n",
    "    ts=t.score(X_test, y_test)\n",
    "    print(\"5 fold cross validation for Decision Tree Classifier:\",ts)\n",
    "    msl.append(ts)\n",
    "    msl = pd.Series(msl)\n",
    "    dt_5fold_values+=[ts]\n",
    "    msl.where(msl==msl.max()).dropna()\n",
    "    accuracy_dt += ts\n",
    "                   \n",
    "print(\"Accuracy for Decision Tree Classifier:\",accuracy_dt/5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold cross validation for Support Vector Machines: 0.34748010610079577\n",
      "5 fold cross validation for Support Vector Machines: 0.41909814323607425\n",
      "5 fold cross validation for Support Vector Machines: 0.38461538461538464\n",
      "5 fold cross validation for Support Vector Machines: 0.4403183023872679\n",
      "5 fold cross validation for Support Vector Machines: 0.4535809018567639\n",
      "Accuracy for Support Vector Machine: 0.4090185676392573\n"
     ]
    }
   ],
   "source": [
    "#Here I am using Support Vector Machines sklearn library and calculating 5-fold cross validation and accuracy\n",
    "from sklearn.svm import SVC\n",
    "accuracy_svm = 0\n",
    "svm_5fold_values=[]\n",
    "for train_index, test_index in skf.split(X_data, y_data):\n",
    "    ##print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X_data[train_index], X_data[test_index]\n",
    "    y_train, y_test = y_data[train_index], y_data[test_index]\n",
    "    ##Support Vector Machine\n",
    "    svm=[]\n",
    "    svc = SVC(gamma = 'scale')\n",
    "    s= svc.fit(X_train, y_train)\n",
    "    cs = s.score(X_test , y_test)\n",
    "    print(\"5 fold cross validation for Support Vector Machines:\",cs)\n",
    "    svm.append(cs)\n",
    "    svm = pd.Series(svm)\n",
    "    svm_5fold_values+=[cs]\n",
    "    svm.where(svm==svm.max()).dropna()\n",
    "    accuracy_svm += cs\n",
    "print(\"Accuracy for Support Vector Machine:\",accuracy_svm/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold cross validation for KNN: 0.26525198938992045\n",
      "5 fold cross validation for KNN: 0.33687002652519893\n",
      "5 fold cross validation for KNN: 0.376657824933687\n",
      "5 fold cross validation for KNN: 0.3713527851458886\n",
      "5 fold cross validation for KNN: 0.363395225464191\n",
      "Accuracy for KNN: 0.34270557029177723\n"
     ]
    }
   ],
   "source": [
    "#Here I am using Support Vector Machines sklearn library and calculating 5-fold cross validation and accuracy\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "accuracy_knn = 0\n",
    "knn_5fold_values=[]\n",
    "for train_index, test_index in skf.split(X_data, y_data):\n",
    "    X_train, X_test = X_data[train_index], X_data[test_index]\n",
    "    y_train, y_test = y_data[train_index], y_data[test_index]\n",
    "    knn = []\n",
    "    \n",
    "    neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    ks = neigh.score(X_test, y_test)\n",
    "    print(\"5 fold cross validation for KNN:\",ks)\n",
    "    knn.append(ks)\n",
    "    knn = pd.Series(knn)\n",
    "    knn_5fold_values+=[ks]\n",
    "    \n",
    "    knn.where(knn == knn.max()).dropna()\n",
    "    accuracy_knn += ks\n",
    "print(\"Accuracy for KNN:\",accuracy_knn/5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold cross validation for Naive bayes: 0.259946949602122\n",
      "5 fold cross validation for Naive bayes: 0.3687002652519894\n",
      "5 fold cross validation for Naive bayes: 0.3819628647214854\n",
      "5 fold cross validation for Naive bayes: 0.41644562334217505\n",
      "5 fold cross validation for Naive bayes: 0.35278514588859416\n",
      "Accuracy for gaus: 0.3559681697612732\n"
     ]
    }
   ],
   "source": [
    "#Here I am using Naive Bayes sklearn library and calculating 5-fold cross validation and accuracy\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "accuracy_gaus = 0\n",
    "bayes_5fold_values=[]\n",
    "for train_index, test_index in skf.split(X_data, y_data):\n",
    "    X_train, X_test = X_data[train_index], X_data[test_index]\n",
    "    y_train, y_test = y_data[train_index], y_data[test_index]\n",
    "    dizi = []\n",
    "    g = GaussianNB()\n",
    "    g.fit(X_train, y_train)\n",
    "    gaussian = g.score(X_test, y_test)\n",
    "    print(\"5 fold cross validation for Naive bayes:\",gaussian)\n",
    "    dizi.append(gaussian)\n",
    "    dizi = pd.Series(dizi)\n",
    "    bayes_5fold_values+=[gaussian]\n",
    "    dizi.where(knn == dizi.max()).dropna()\n",
    "    accuracy_gaus += gaussian\n",
    "print(\"Accuracy for gaus:\",accuracy_gaus/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>SVM</th>\n",
       "      <th>kNN</th>\n",
       "      <th>Naive Bayes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.262599</td>\n",
       "      <td>0.347480</td>\n",
       "      <td>0.265252</td>\n",
       "      <td>0.259947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.326260</td>\n",
       "      <td>0.419098</td>\n",
       "      <td>0.336870</td>\n",
       "      <td>0.368700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.273210</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.376658</td>\n",
       "      <td>0.381963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.283820</td>\n",
       "      <td>0.440318</td>\n",
       "      <td>0.371353</td>\n",
       "      <td>0.416446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.326260</td>\n",
       "      <td>0.453581</td>\n",
       "      <td>0.363395</td>\n",
       "      <td>0.352785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Decision Tree       SVM       kNN  Naive Bayes\n",
       "0       0.262599  0.347480  0.265252     0.259947\n",
       "1       0.326260  0.419098  0.336870     0.368700\n",
       "2       0.273210  0.384615  0.376658     0.381963\n",
       "3       0.283820  0.440318  0.371353     0.416446\n",
       "4       0.326260  0.453581  0.363395     0.352785"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here I am creating a dataset only contains 5-fold cross validation results because I will use them for making\n",
    "#box plotes for better visualization\n",
    "\n",
    "values = {'Decision Tree':dt_5fold_values, \n",
    "        'SVM': svm_5fold_values, \n",
    "          'kNN':knn_5fold_values,\n",
    "        'Naive Bayes': bayes_5fold_values} \n",
    "\n",
    "df = pd.DataFrame(values) \n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f6129a3fc8>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.boxplot(column=['Decision Tree','SVM','kNN','Naive Bayes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
